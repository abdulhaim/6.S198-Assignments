<!DOCTYPE html>
<html>
	<head>
		<title>Assignment 3</title>
		<link rel="stylesheet" type="text/css" href="css/main.css">
	</head>
	<body>
		<h1> Assignment 3 </h1>
		<h3> <i> Due Monday September 24th at 10 AM </i> </h3>


		<h2> <b> 1.4: Visualizing convolutional neural networks</b> </h2>

		   <p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

		   	The visualization demo below by Adam Harley shows a network with 2 convolutional layers, two fully connected layers, and two max pool layers (for downsampling).

		   	http://scs.ryerson.ca/~aharley/vis/conv/flat.html 

		   	After playing with the demo and drawing different kinds of inputs with various features, I observed the following: 

		   	1. The network works pretty well for a number that is drawn perfectly straight on the screen.

		   	<br/> <br/>

			<img src="images/assignment_3/perfect_number.png" alt="Teachable Machine" align="middle" height="300" width="300" />

			<br/> <br/>

		   	2. The network is unable to decipher what the number is if it is even a bit slanted.

		   	<br/> <br/>

			<img src="images/assignment_3/slanted_number.png" alt="Teachable Machine" align="middle" height="300" width="300" />

			<br/> <br/>

		   	3. The network is unable to decipher what the number is if it is upside down.


		   	<br/> <br/>

			<img src="images/assignment_3/upside_down_number.png" alt="Teachable Machine" align="middle" height="300" width="300" />

			<br/> <br/>

		   	4. The network is able to recognize only some numbers when they are bolded. 


		   	<br/> <br/>

			<img src="images/assignment_3/thick_number.png" alt="Teachable Machine" align="middle" height="300" width="300" />

			<br/> <br/>

			<img src="images/assignment_3/thick_number_2.png" alt="Teachable Machine" align="middle" height="300" width="300" />

			<br/> <br/>

			<img src="images/assignment_3/thick_number_3.png" alt="Teachable Machine" align="middle" height="300" width="300" />


		   	5. For a completely colored in image, the network spits out "1". This was consistent behaviour.


			<img src="images/assignment_3/white_image.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>


			It also spits out a random number for invalid inputs. 

			<br/> <br/>


			<img src="images/assignment_3/invalid.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			6. The network gets easily confused for unclear numbers 

			<img src="images/assignment_3/not_clear.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>


		    </p>

			<h2> <b> 2. Style Transfer Examples </b> </h2>

			<p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

			Style transfer is an application of convolutional neural networks. Given a content image and a style (another image), we can apply a computation that transforms the content to match the selected style.

			Here are some of the examples I created on DeepArt:

			<br/> <br/>

			<img src="images/assignment_2/deep_art_1.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_2/deep_art_2.png" alt="Teachable Machine" align="middle" height="200" width="600" />
			
			</p>

			<h2> <b> 3.5: Fast Style Transfer </b> </h2>

			<p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

			We use the Fast Neural Style Transfer link below for the following question: 

			https://reiinakano.github.io/fast-style-transfer-deeplearnjs

			1. When passing an image through the same filter several times, I noticed that the image changes drastically in the first pass and doesnt change much after passing the filter a 3rd and 4th time. The details in the image get blurred out. 

			<img src="images/assignment_3/first_filter.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_3/second_filter.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_3/third_filter.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_3/fourth_filter.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>


			2. The next task that I did is to apply the filter "Rain Princess, Leonid Afremov" to the image above and then apply "The Wave - Katsushika Hokusai" filter to the resulting image from the first filter. The first image has only only the Katsushika Hokusai filter applied, whereas the second picture has both filters applied. 

			<img src="images/assignment_3/diana_transfer1.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<img src="images/assignment_3/diana_transfer2.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			The result is not similar to applying the second filter to the original image as the image has already been transformed by the first filter. The style may be the same but there are different features and details in the two images as shown. 

			<br/> <br/>

			3. Here I have tried different combinations of filters/number of times I filter the image.


			Trial 1: Image filtered with "Rain Princess", "La Muse", "Udnie", "The Wreck of the Minotaur", "The Wave" and "The Scream" respectively. We start with the original image below. The final image does not looks very different to what it would have looked like had we only applied "The Scream" filter (the last image shown in this series).

			<br/> <br/>

			<img src="images/assignment_3/0.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_3/1.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>


			<img src="images/assignment_3/2.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_3/3.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_3/4.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_3/5.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_3/the_scream.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			</p>


			<h2> <b> 3.6 Building CNNs with code </b> </h2>

			<p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

			<WRITEUP REQUIRED>
			Similar to the work you did with Model Builder on Monday, investigate several choices of architectures and hyperparameters for classifying images from MNIST, Fashion MNIST, and CIFAR_10 working from your .js and .html files from last week.  You’ll need to change the code where it says “Building the model” to construct new networks of your choice.  In addition to the constructor functions from last week, the .js code already has functions for adding convolutional and max pool layers.  For the following 4 questions, describe what architectures you implemented and take screenshots of the results you got for each dataset (MNIST, Fashion MNIST, and CIFAR).

			1. Try changing the learning rate, batch size, and number of batches. Make sure that these numbers are reasonable to start (i.e. won't take too long to run on your computer).

			2. Try changing some of the other parameters like field size, stride, output, …

			3. Do you have a hypothesis for why CIFAR-10 is so much harder to train on than Fashion MNIST and MNIST (i.e. it’s more difficult to achieve a 90%+ accuracy) while Fashion MNIST has similar training times to MNIST (even though Fashion MNIST is more complex than MNIST)?

			4. How does adding more convolutional layers relate to accuracy and training speed? Is there a point at which adding more layers plateaus or even decreases the maximum accuracy you are able to achieve with that model?

			5. Challenge: Are you able to find an architecture/combination of techniques that can get you to 60% accuracy on CIFAR-10 within 1 minute of training? 5 minutes? 10 minutes?

			<WRITEUP REQUIRED>
			6. Add code that captures some performance statistic from a testing run.  For example, you might keep track of the fraction of examples where the prediction was correct , or perhaps do something more detailed that takes the predicted probabilities into account.  Hint: Look near the end of the file where the testing results are logged. Using your performance metrics, compare some of the different models you built above.  Write a brief report with screenshots showing the choices and the results.

			<WRITEUP REQUIRED>
			7. Add links to your code files on your website (please make sure these are text files and not screenshots so that the graders can run your code if necessary).



			</p>


		</body>



	</body>

</html>





