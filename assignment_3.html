<!DOCTYPE html>
<html>
	<head>
		<title>Assignment 3</title>
		<link rel="stylesheet" type="text/css" href="css/main.css">
	</head>
	<body>
		<h1> Assignment 3 </h1>
		<h3> <i> Due Monday September 24th at 10 AM </i> </h3>

		<h2> <b> 1.4: Visualizing convolutional neural networks</b> </h2>

		   <p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

		   	The visualization demo below by Adam Harley shows a network with 2 convolutional layers, two fully connected layers, and two max pool layers (for downsampling).

		   	http://scs.ryerson.ca/~aharley/vis/conv/flat.html 

		   	After playing with the demo and drawing different kinds of inputs with various features, I observed the following: 

		   	1. The network works pretty well for a number that is drawn perfectly straight on the screen.

		   	<br/> <br/>

			<img src="images/assignment_3/perfect_number.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

		   	2. The network is unable to decipher what the number is if it is even a bit slanted.

		   	<br/> <br/>

			<img src="images/assignment_3/slanted_number.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

		   	3. The network is unable to decipher what the number is if it is upside down.


		   	<br/> <br/>

			<img src="images/assignment_3/upside_down_number.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

		   	4. The network is able to recognize only some numbers when they are bolded. 


		   	<br/> <br/>

			<img src="images/assignment_3/thick_number.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

			<img src="images/assignment_3/thick_number_2.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

			<img src="images/assignment_3/thick_number_3.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

		   	5. For a completely colored in image, the network spits out "1". This was consistent behaviour.

			<br/> <br/>

			<img src="images/assignment_3/white_image.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

			It also spits out a random number for invalid inputs. 

			<br/> <br/>


			<img src="images/assignment_3/invalid.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

			6. The network gets easily confused for unclear numbers 

			<br/> <br/>

			<img src="images/assignment_3/not_clear.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>


		    </p>

			<h2> <b> 2. Style Transfer Examples </b> </h2>

			<p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

			Style transfer is an application of convolutional neural networks. Given a content image and a style (another image), we can apply a computation that transforms the content to match the selected style.

			Here are some of the examples I created on DeepArt:

			<br/> <br/>

			<img src="images/assignment_2/deep_art_1.png" alt="Teachable Machine" align="middle" height="200" width="600" />

			<br/> <br/>

			<img src="images/assignment_2/deep_art_2.png" alt="Teachable Machine" align="middle" height="200" width="600" />
			
			</p>

			<h2> <b> 3.5: Fast Style Transfer </b> </h2>

			<p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

			We use the Fast Neural Style Transfer link below for the following question: 

			<br/> <br/>

			https://reiinakano.github.io/fast-style-transfer-deeplearnjs
			
			<br/> <br/>


			1. When passing an image through the same filter several times, I noticed that the image changes drastically in the first pass and doesnt change much after passing the filter a 3rd and 4th time. The details in the image get blurred out.

			<br/> <br/>
 

			<img src="images/assignment_3/first_filter.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

			<img src="images/assignment_3/second_filter.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

			<img src="images/assignment_3/third_filter.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

			<img src="images/assignment_3/fourth_filter.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>


			2. The next task that I did is to apply the filter "Rain Princess, Leonid Afremov" to the image above and then apply "The Wave - Katsushika Hokusai" filter to the resulting image from the first filter. The first image has only only the Katsushika Hokusai filter applied, whereas the second picture has both filters applied. 

			<img src="images/assignment_3/diana_transfer1.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<img src="images/assignment_3/diana_transfer2.png" alt="Teachable Machine" align="middle" height="300" width="400" />

			<br/> <br/>

			The result is not similar to applying the second filter to the original image as the image has already been transformed by the first filter. The style may be the same but there are different features and details in the two images as shown. 

			<br/> <br/>

			3. Here I have tried different combinations of filters/number of times I filter the image.


			Trial 1: Image filtered with "Rain Princess", "La Muse", "Udnie", "The Wreck of the Minotaur", "The Wave" and "The Scream" respectively. We start with the original image below. The final image does not looks very different to what it would have looked like had we only applied "The Scream" filter (the last image shown in this series).

			<br/> <br/>

			<img src="images/assignment_3/0.jpg" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>

			<img src="images/assignment_3/1.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>


			<img src="images/assignment_3/2.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>

			<img src="images/assignment_3/3.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>

			<img src="images/assignment_3/4.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>

			<img src="images/assignment_3/5.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>

			<img src="images/assignment_3/the_scream.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			</p>


			<h2> <b> 3.6 Building CNNs with code </b> </h2>

			<p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

			Here, I investigate several choices of architectures and hyperparameters for classifying images from MNIST, Fashion MNIST, and CIFAR_10. 

			1. After changing the learning rate, batch size, and number of batches to:

			BATCH_SIZE = 300
			NUM_BATCHES = 200
			learning_rate = 0.1

			<br/> <br/>

			For MNIST:

			<br/> <br/>

			<img src="images/assignment_3/mnist_same_arch.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>

			For Fashion MNIST:

			<br/> <br/>

			<img src="images/assignment_3/fashion_mnist_same_arch.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>

			For CIFAR_10:

			<br/> <br/>

			<img src="images/assignment_3/cifar_same_arch.png" alt="Teachable Machine" align="middle" height="200" width="300" />

			<br/> <br/>

			2. I also changed the parameters including field size, stride, and the output:

			<br/> <br/>

			3. My hypothesis as to why CIFAR-10 is so much harder to train on than Fashion MNIST and MNIST because CIFAR-10 is in color whereas the MNIST datasets are black and white (so there are 3 input layers to account for color for CIFAR-10).

			<br/> <br/>

			4. Adding more convolutional layers increases accuracy up to 5-6 layers when the accuracy begins to decrease. Whereas as you increase the number of layers, the training speed also increases as the network takes longer to train. 

			<br/> <br/>

			5. I was able to find an architecture/combination of techniques that gets an accuracy of 60% accuracy on CIFAR-10 within only 10 minutes of training as shown below: 

			<br/> <br/>

			6. Here is the code I added to capture some performance statistics from the testing runs. I kept track of the fraction of examples where the prediction was correct.

			7. Link to the index.js file:

			<br/> <br/>


			</p>


		</body>



	</body>

</html>





