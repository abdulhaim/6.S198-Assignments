<!DOCTYPE html>
<html>
	<head>
		<title> Assignment 4: Embeddings and Generative Models </title>
		<link rel="stylesheet" type="text/css" href="css/main.css">
	</head>
	<body>
		<h1> Assignment 4: Embeddings and Generative Models </h1>
		<h3> <i> Due Wednesday October 10th at 10 AM </i> </h3>

		<h2> <b>  1.1 Visualizing Datasets using the Embedding Projector </b> </h2>

		   <p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 
			
			Problem 1: Spend some time using the embedding projector to make and share observations about the MNIST data. Do the different digits separate into distinct clouds? Are there images that are in the wrong cloud, and can you make sense of why they are wrong? Are there images that are outliers from the rest of the data? Are there digits that seem more separate from the others, and are there pairs of digits that are more easily confused? 

			<br/> <br/>
			The different digits do seperate out into seperate clouds, with some outliers present in cases where the digit could be misclassified due to the way they are written (slanted, enlarged, etc) which makes them look like another digit. These observations happens for both projection methods PCA and t-SNE. 

			<br/> <br/>

			Principal Component Analysis (PCA).  PCA maps the data onto the dimensions along which the data has the greatest variation, the next greatest variation, and so on. On the other hand, t-SNE (t-Distributed Stochastic Neighboring Entities) chooses 3 axis such that the distances between the projected points in 3 dimensions are close to the distances between the points the high-dimensional space. This is done by an iterative computation where the distance difference is reduced step by step. Due to this difference between the two methods, PCA has a greater tendency to misclassify numbers as other numbers as it chooses the directions with the greatest difference between them. 

			<br/> <br/>

			You can see the cloud generated by PCA here:

			<br/> <br/>

		   	<img src="images/assignment_4/pca_cloud.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

			You can see the cloud generated by t-SNE here:

			<br/> <br/>

		   	<img src="images/assignment_4/t-SNE.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

			The pairs of digits that are most easily confused include 0 & 2, 0 & 9, 2 & 7, and 3 & 8. 

			The digits that are most distinct include 1, 6, and 2. 

			<br/> <br/>

		   </p>

		   <h2> <b>  1.3 Word Geometry </b> </h2>

		   <p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 
			
			Problem 2: Remember that this geometry is not based on any word definitions, but rather only the frequencies with which words co-occur in phrases. Also keep in mind that the vertical positions of the words are random, although you can specify these, too, by setting “up” and “down”. Experiment with various words to see if you can identify any insights about the data set. For example, try “politics” along the dimension from “bad” to “good”, or “engineer” along the spectrum from “man” to “woman”. Write up some notes on your observations, perhaps supplemented with a few pictures. Do you get different or better results if you use Word2Vec All instead of 10K? Did you find any interesting examples that speak to how words are used news articles? 

			<br/> <br/>

			To begin, I ran an experiment with the word "islam" along the dimension from “bad” to “good”. For the word islam, I get the words "worship" and "spiritual" on the good side, and the words "palestine" and "militant" on the bad side. I find this to be very interesting and also confusing, as I am not sure what they are using as their metric of good and bad. However, it makes sense wit how Islam is protrayed in the news and media. 

			<br/> <br/>

		   	<img src="images/assignment_4/1.3_islam.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

		   	I also tried out the word "engineer" with man and woman on either side. Its interesting how on the side with woman, you see the words "artist", "dancer", whereas on the side of man you see "inventors" and "electronics".

			<br/> <br/>

		   	<img src="images/assignment_4/1.3_engineer.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

		   	When trying this experiment with the Word2Vec All dataset instead of the Word2Vec 10K dataset, I do not get better results but very different ones as now the sample size to check for frrequencies with which words co-occur in phrases is smaller. I got more skewed results 

		   </p>

		   <h2> <b>  1.4: Finding Word Analogies with Vector Algebra  </b> </h2>

		   <p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

			Problem 3: Spend a few minutes experimenting with the demo on https://rare-technologies.com/word2vec-tutorial/ (under “Bonus App”) which uses Word2Vec vector algebra to solve analogies.  Make a note of any interesting examples you find.

			<br/> <br/>

			As usual, I tried to ask very simple analogies to the model and it performed pretty well as shown: 

			<br/> <br/>

			<img src="images/assignment_4/Works_Well_Jesus_Allah.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

			<img src="images/assignment_4/Work Well_Christianity_Islam.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

			<img src="images/assignment_4/girl_boy.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

			It is interesting that the demo is very sensitive to capitalization and even order of the words as shown below:

			<br/> <br/>

			<img src="images/assignment_4/order_matters_normal.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

			<img src="images/assignment_4/order_matters.png" alt="Corr Map" align="middle" height="300" width="400" />

			<br/> <br/>

			If the relationship between the first two words is not clear, the model returns the most similar word or the same word as shown below:

			<img src="images/assignment_4/dummy.png" alt="Corr Map" align="middle" height="300" width="400" />


		   </p>

		   <h2> <b>  1.5: Exploring fonts with the Embedding Projector   </b> </h2>

		   <p style = "font-size:18px ; line-height: 1.4em; color: #333 "> 

		   	Problem 4: Navigate to this link to look at different embedding spaces for fonts: goo.gl/F3tjgs.

			1. View the fonts with PCA embedding. Do you see any clumps/areas with obvious characteristics? Record a few Font IDs for distinct characteristics/groupings that you find interesting (hover over a character to get its font ID), such as bold, italics, cursive...etc. You will use this in the homework.

			2. Change to the embedding to T-SNE. Record how many iterations you let T-SNE run for for and whether or not you were able to get interesting groupings. Again, record Font IDs for interesting fonts/groupings.

			3. Find a font you like, get its ID, and type that into the search bar at the right-hand side of the screen. Use the "neighbors" slider to isolate a few dozen points and record the Font IDs of the 10 nearest neighbors that make sense. Repeat this for 3 or 4 fonts. If you find a font that doesn't have nearest neighbors that look similar, note that down as well.


			</p>

		</body>



	</body>

</html>


